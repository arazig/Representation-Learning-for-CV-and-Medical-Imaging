{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial examples - Blind spot in representation spaces\n",
    "### Author: Pietro Gori\n",
    "\n",
    "As for all TP, answer all questions and fill the code where you see **XXXXXXXXX**\n",
    "\n",
    "**Deadline**: please verify on the Moodle/Ecampus/web site the deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PgLwOcWEW6kB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset, TensorDataset\n",
    "\n",
    "# torchvision\n",
    "from torchvision import models,transforms\n",
    "import torchvision.datasets as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session, you will produce adversarial examples using two strategies to analyse the quality and smoothness of a representation space. We will use the Mnist dataset and a simple network (with 97% accuracy on test though...) so that you can train and test on your own laptop. Same conclusions can be drawn by using larger architectures and more complex datasets (You can try if you want).\n",
    "\n",
    "Let's start with the first method. Please read first the article [1], in particular from Sectioon 4. \n",
    "\n",
    "`[1] Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian J.,\n",
    "and Fergus, Rob. Intriguing properties of neural networks. ICLR, 2014`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first check if you are using a computer with GPU, CUDA (Nvidia) or MPS (MacBook), or only CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.2.2\n",
      "tensor([1.])\n",
      "No MPS or CUDA has been found. PyTorch will use CPU.\n"
     ]
    }
   ],
   "source": [
    "print(\"Using torch\", torch.__version__)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)    \n",
    "    print (\"MPS (MacBook) device found.\")\n",
    "    print('Number of MPS cards: ', torch.mps.device_count())\n",
    "    print('Total MPS memory {0:.2f} GB'.format(torch.mps.recommended_max_memory()/pow(10,9)))\n",
    "elif torch.backends.cuda.is_built():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x) \n",
    "    print (\"CUDA device found.\")\n",
    "    print('Number of GPU cards: ', torch.cuda.device_count(), '\\nWhich card GPU?', torch.cuda.get_device_name(0))\n",
    "    print('Total GPU memory {1:.2f} GB. Free GPU memory {0:.2f} GB'.format(torch.cuda.mem_get_info()[0]/pow(10,9),torch.cuda.mem_get_info()[1]/pow(10,9)))\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "   x = torch.ones(1, device=device)\n",
    "   print(x) \n",
    "   print('No MPS or CUDA has been found. PyTorch will use CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fix the different seeds to make your algorithm reproducible and we set the hyper-parameters for the classification model we are going to train. You can modify them if you want, but I suggest you keep them like that for now and modify them only AFTER having trained for a first time the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oLSejbV7XBTM"
   },
   "outputs": [],
   "source": [
    "# to make the results reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "torch.mps.manual_seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "\n",
    "# Parameters for training model\n",
    "weight_decay = 0\n",
    "num_epochs = 5\n",
    "batch_size=256 # adapted to the Google Colab GPU\n",
    "learning_rate=0.001\n",
    "loss_model=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the MNIST dataset. Download it from torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hLLzZxjeXHkZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 11126124.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 333209.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3209698.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1339511.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = Data.MNIST(root='data/',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "train_loader  = DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "mnist_test = Data.MNIST(root='data/',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "test_loader  = DataLoader(dataset=mnist_test,\n",
    "                                          batch_size=10000,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyse the data to check the number of samples and their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DmKGxc6-ss18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  60000 training images and  10000 test images\n",
      "Each image is of shape: [28, 28]\n"
     ]
    }
   ],
   "source": [
    "# Print infomration\n",
    "print(\"There are \", len (mnist_train), \"training images and \", len(mnist_test), \"test images\")\n",
    "image_size=list(mnist_train[0][0].squeeze().shape)\n",
    "print(f\"Each image is of shape: {image_size}\")  # [28, 28]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we code the model proposed in the article. \n",
    "\n",
    "**Question**: complete the code so that you can create *A simple fully connected network with one or more hidden layers and a Softmax classifier. We refer to this network as “FC”*. Please code it so that the input_size of the model (i.e. size of the input images), the number and size of hidden layers (e.g., [100,100]) and the output size (i.e., number of possible classes) are parameters of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fQqurhGdaPSg"
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.number_layers = hidden_sizes[0]\n",
    "        self.layers_size = hidden_sizes[1]\n",
    "        self.layers = []\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.layers.append(nn.Linear(self.input_size, self.layers_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(self.number_layers):\n",
    "            self.layers.append(nn.Linear(self.layers_size, self.layers_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.layers.append(nn.Linear(self.layers_size, self.output_size))\n",
    "        self.layers.append(nn.Softmax())\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = x.flatten(start_dim=1)\n",
    "        output = self.model(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Create one of the model proposed in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ww7Rs2pMbSlv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedNet(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (23): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = image_size[0]*image_size[1]\n",
    "hidden_sizes = [10,10]\n",
    "output_size = 10\n",
    "\n",
    "# Model\n",
    "model = FullyConnectedNet(input_size, hidden_sizes, output_size).to(device)\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Print the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we code the training procedure, as commonly done with Pytorch. Please note that we use the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s3-YeNkK-_MF"
   },
   "outputs": [],
   "source": [
    "def training(model, train_loader, optimizer, num_epochs, loss_model):\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # Put images to GPU\n",
    "        X = images.to(device)\n",
    "        Y = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = loss_model(outputs, Y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aAvlZBsv_fGi"
   },
   "outputs": [],
   "source": [
    "def evaluation(model, test_loader):\n",
    "  model.eval()\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for images, labels in test_loader:\n",
    "\n",
    "      X  = images.to(device)\n",
    "      Y  = labels.to(device)\n",
    "\n",
    "      outputs = model(X) # array of size [num test images, num classes]\n",
    "\n",
    "      predicted_class = torch.argmax(outputs.data, dim=1) # faster\n",
    "\n",
    "      total += len(Y)\n",
    "      correct += (predicted_class == Y).sum()\n",
    "\n",
    "  print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P3DILmTwqd01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aminerazig/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/235], Loss: 2.3001\n",
      "Epoch [1/5], Step [200/235], Loss: 2.1309\n",
      "Epoch [2/5], Step [100/235], Loss: 1.9907\n",
      "Epoch [2/5], Step [200/235], Loss: 1.9110\n",
      "Epoch [3/5], Step [100/235], Loss: 1.8651\n",
      "Epoch [3/5], Step [200/235], Loss: 1.9026\n",
      "Epoch [4/5], Step [100/235], Loss: 1.8265\n",
      "Epoch [4/5], Step [200/235], Loss: 1.8695\n",
      "Epoch [5/5], Step [100/235], Loss: 1.8611\n",
      "Epoch [5/5], Step [200/235], Loss: 1.8351\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "training(model, train_loader, optimizer, num_epochs, loss_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4vFdz_Ar8mLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 64.780000 %\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is the performance good ? Test different architectures (number and size of hidden layers). You can also try different hyper-parameters (weight decay, number of epochs, etc.). Use the \"Occam's razor principle\" to choose and justify your final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/235], Loss: 2.2109\n",
      "Epoch [1/5], Step [200/235], Loss: 2.0616\n",
      "Epoch [2/5], Step [100/235], Loss: 1.9388\n",
      "Epoch [2/5], Step [200/235], Loss: 1.8560\n",
      "Epoch [3/5], Step [100/235], Loss: 1.8133\n",
      "Epoch [3/5], Step [200/235], Loss: 1.8210\n",
      "Epoch [4/5], Step [100/235], Loss: 1.8532\n",
      "Epoch [4/5], Step [200/235], Loss: 1.8129\n",
      "Epoch [5/5], Step [100/235], Loss: 1.8115\n",
      "Epoch [5/5], Step [200/235], Loss: 1.7193\n",
      "Accuracy of test images: 69.220000 %\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes =[10,20]\n",
    "\n",
    "model = FullyConnectedNet(input_size, hidden_sizes, output_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "training(model, train_loader, optimizer, num_epochs, loss_model)\n",
    "evaluation(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :**\n",
    "\n",
    "**With the initial architecture 10 hidden layers of size 10 we see that the performance is quiet low. I chose the architecture and the hyperparamters above (10 hidden layers of 20 neuronnes) to improve performance for the following reasons : the error was still decreasing at epoch 5 which means that the model was still learning so increasing the numbers of epoch give a better accuracy. I simply preferred to increase the layer size rather than the number of layers, because the vanishing gradient.**\n",
    "\n",
    "-----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h46ZMx5gAXlp"
   },
   "source": [
    "Here, you will code the method proposed in Sec. 4.1 of [1]. I copy/paste it here:\n",
    "\n",
    "We denote by $f : R^m \\rightarrow {1 . . . k}$ a classifier mapping image pixel value vectors to a discrete label set. We also assume that $f$ has an associated continuous loss function denoted by $\\text{loss}_f : R^m × {1 . . . k} \\rightarrow R^+$. For a given $x \\in R^m$ image and target label $l \\in {1 . . . k}$, we aim to solve the following box-constrained optimization problem:\n",
    "\n",
    "• Minimize $||r||_2$ subject to:\n",
    "1. $f(x + r) = l$\n",
    "2. $x + r \\in [0, 1]^m$\n",
    "\n",
    "\n",
    "The minimizer $r$ might not be unique, but we denote one such $x + r$ for an arbitrarily chosen minimizer by $D(x, l)$. Informally, $x + r$ is the closest image to $x$ classified as $l$ by $f$. Obviously, $D(x, f(x)) = f(x)$, so this task is non-trivial only if $f(x) \\neq l$. In general, the exact computation\n",
    "of $D(x, l)$ is a hard problem, so we approximate it by using a box-constrained L-BFGS. Concretely, we find an approximation of $D(x, l)$ by performing line-search to find the minimum $c > 0$ for which the minimizer $r$ of the following problem satisfies $f(x + r) = l$.\n",
    "\n",
    "• Minimize $c|r| + \\text{loss}_f (x + r, l)$ subject to $x + r \\in [0, 1]^m$\n",
    "\n",
    "This penalty function method would yield the exact solution for $D(X, l)$ in the case of convex losses, however neural networks are non-convex in general, so we end up with an approximation in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by setting the hyper-parameters of the L-BFGS method. Keep them like that for now. You will come back later to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzGk985F4ZOd"
   },
   "outputs": [],
   "source": [
    "# Parameters adversarial example\n",
    "index=666 # index test image to use\n",
    "\n",
    "max_iter_search=3000\n",
    "initial_c = 0.000001  # Initial value of c\n",
    "max_c = 0.1  # Upper limit for c\n",
    "mult_c = 1.03 # Multiplicative update of c at each iter c *= mult_c\n",
    "\n",
    "epsilon_LBFGS = 1e-6  # Small value for line search stopping criterion\n",
    "max_iter_LBFGS = 100  # Maximum iterations for L-BFGS\n",
    "lr_LBFGS = 0.1  # Learning rate for L-BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the chosen image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVfomQKy9LSi"
   },
   "outputs": [],
   "source": [
    "testI, testY = mnist_test.__getitem__(index)\n",
    "fig = plt.imshow(testI.squeeze(), interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title(f\"Correct class is {testY}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a code to plot the original image $x$, the modified image $x+r$ and the residual added $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X, r, Xr, Y, l, fail=True):\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25, 7))\n",
    "    im1 = axes[0].imshow(X.squeeze().cpu().detach().numpy(), interpolation='nearest', cmap=plt.cm.gray)\n",
    "    axes[0].set_title(f\"Original Image. Correct class is {Y}\",fontsize=22)\n",
    "\n",
    "    im3=axes[2].imshow(r.squeeze().cpu().detach().numpy(), interpolation='nearest', cmap=plt.cm.gray)\n",
    "    axes[2].set_title(f\"Residual added\",fontsize=22)\n",
    "\n",
    "    if fail:\n",
    "        im2=axes[1].imshow(Xr.squeeze().cpu().detach().numpy(), interpolation='nearest', cmap=plt.cm.gray)    \n",
    "        axes[1].set_title(f\"Modified Image, FAILED to predict class {l.item()}\",fontsize=22)\n",
    "    else:\n",
    "        im2=axes[1].imshow(Xr.squeeze().cpu().detach().numpy(), interpolation='nearest', cmap=plt.cm.gray)    \n",
    "        axes[1].set_title(f\"Modified Image, PREDICTED class {l.item()}\",fontsize=22)\n",
    "\n",
    "    # Add a single colorbar for all subplots\n",
    "    cbar = fig.colorbar(im3, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Intensity (0 to 1)')\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPdOsg9L6ulW"
   },
   "source": [
    "Here we will code the proposed method. Complete the code where you see `XXXXXXX`.\n",
    "\n",
    "Please be advised that the `torch.optim.LBFGS` optimizer is designed to work with a `closure` for computing the loss and gradients multiple times during optimization, which is essential for second-order methods.\n",
    "\n",
    "The closure is a callable function passed to LBFGS that recomputes the loss and its gradients multiple times during a single optimization step.\n",
    "To work correctly, we need to call `optimizer.zero_grad()` to clear old gradients before calculating new ones.\n",
    "\n",
    "Please note that SGD or Adam don't require a closure because they update the parameters based on the current gradient in a single step.\n",
    "\n",
    "More info here: https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcZNY6pFx6kq"
   },
   "outputs": [],
   "source": [
    "testI=testI.to(device)\n",
    "r = torch.zeros_like(testI, requires_grad=True, device=device)  # Initialize r as zero\n",
    "label= testY-6 # manually chosen target class label different from true one\n",
    "l = torch.tensor([label]).to(device)  \n",
    "l=l.to(device)\n",
    "l = l.view(1) # to have a batch size equal to 1 and work with CrossEntropy loss\n",
    "print(f\"The true class is {testY}, the new class will be {l[0]}\")\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def objective(c, r, x, l):\n",
    "    term1 = c * torch.norm(r)\n",
    "    term2 = loss_model(model(x+r), l)\n",
    "    return term1 + term2\n",
    "\n",
    "\n",
    "# Line search to find the minimum c > 0\n",
    "c = initial_c\n",
    "iter=0\n",
    "while (c <= max_c) and (iter <= max_iter_search):    \n",
    "    # Define the optimizer (Box-Constrained L-BFGS)\n",
    "    optimizerLBFGS = optim.LBFGS([r])\n",
    "\n",
    "    def closure():\n",
    "      optimizerLBFGS.zero_grad()\n",
    "      loss = objective(c, r, testI, l)\n",
    "      loss.backward()\n",
    "      return loss\n",
    "\n",
    "    # Perform optimization\n",
    "    optimizerLBFGS.step(closure)\n",
    "\n",
    "\n",
    "    # Evaluate the condition f(x + r) = l\n",
    "    with torch.no_grad():\n",
    "        x_r = torch.clamp(testI + r, 0, 1)  # Ensure x + r ∈ [0, 1]^m\n",
    "        pred = model(x_r)\n",
    "        predicted_label = torch.argmax(pred, dim=1)\n",
    "\n",
    "    # Check if the condition f(x + r) = l is satisfied\n",
    "    if predicted_label == l:\n",
    "        print(f\"Found c = {c:.6f} satisfying f(x + r) = l\")\n",
    "        iter=iter+1\n",
    "        break\n",
    "    else:\n",
    "        iter=iter+1\n",
    "\n",
    "    # If not satisfied, increase c\n",
    "    c = c + 0.00001 # Adjust step size for line search\n",
    "    if (iter) % 20 == 0:\n",
    "        print(f'Iter {iter}/{max_iter_search}, Value of c: {c:.6f}')\n",
    "\n",
    "if (c > max_c) or (iter > max_iter_search):\n",
    "    print(\"Failed to find c satisfying f(x + r) = l within the maximum limit of c and max number of iter.\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Optimization succeeded with c = {c:.6f} in {iter} iterations\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION** Try with different images and different predicted classes (l), does the algorithm always converge ? You can test with different hyper-parameters for c. When it converges, are the images semantically similar to the original one ? Visually, would you say that they should belong to the original or new class ? What's the average distortion (norm of r) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What if you try with different networks ? Test with al least another network (i.e., change hidden_sizes) and see if the previous conclusions are still confirmed. \n",
    "\n",
    "Furthermore, check the cross-network performance. This means:\n",
    "- produce a set of adversarial instances for a given network (samples that are visually similar to the original class but recognised by the network as belonging to a different class)\n",
    "- check if these adversarial examples are also wrongly classified by the other network\n",
    "\n",
    "Which conclusions can you draw from these results ? Please comment on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead than using L-BFGS to find adversarial examples we could also use a backpropagation method such as Adam, where you could optimize only r or both r and c. \n",
    "\n",
    "**Question** Change the previous code to use Adam instead than L-BFGS for the optimization. This means that you don't do anymore a line-search to find the minimum $c$ (no more closure). You can either fix $c$ and estimate only $r$ or estimate both. Try these two solutions and comment on that. Does it work properly ? If not, try to change the loss function. Would you add a regularization term ? If yes, which one and why ? Does it work better ? Please comment on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r and c optimized\n",
    "\n",
    "If we optimize jointly both parameters, we have a negative c. We need to change the loss function by taking the absolute value of c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI=testI.to(device)\n",
    "r = torch.zeros_like(testI, requires_grad=True, device=device)  # Initialize r as zero\n",
    "label= testY-4 # manually chosen target class label different from true one\n",
    "l = torch.tensor([label]).to(device)  \n",
    "l=l.to(device)\n",
    "l = l.view(1) # to have a batch size equal to 1 and work with CrossEntropy loss\n",
    "print(f\"The true class is {testY}, the new class will be {l[0]}\")\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def objective(c, r, x, l):\n",
    "    term1 = torch.absolute(c) * torch.norm(r)\n",
    "    term2 = loss_model(model(x+r), l)\n",
    "    return term1 + term2\n",
    "\n",
    "\n",
    "# Line search to find the minimum c > 0\n",
    "c = initial_c\n",
    "c = torch.tensor([c]).to(device)  \n",
    "c = torch.nn.Parameter(c)\n",
    "iter=0\n",
    "\n",
    "# Define the optimizer (Adam Optimizer)\n",
    "optimizerAdam = optim.Adam([r, c])\n",
    "\n",
    "while (c <= max_c) and (iter <= max_iter_search):    \n",
    "\n",
    "    # Perform optimization\n",
    "    loss = objective(c, r, testI, l) #The loss is our objective function\n",
    "    loss.backward()\n",
    "    optimizerAdam.step(closure)\n",
    "\n",
    "\n",
    "    # Evaluate the condition f(x + r) = l\n",
    "    with torch.no_grad():\n",
    "        x_r = torch.clamp(testI + r, 0, 1)  # Ensure x + r ∈ [0, 1]^m\n",
    "        pred = model(x_r)\n",
    "        predicted_label = torch.argmax(pred, dim=1)\n",
    "\n",
    "    # Check if the condition f(x + r) = l is satisfied\n",
    "    if predicted_label == l:\n",
    "        print(f\"Found c = {c.item():.6f} satisfying f(x + r) = l\")\n",
    "        iter=iter+1\n",
    "        break\n",
    "    else:\n",
    "        iter=iter+1\n",
    "\n",
    "    if (iter) % 20 == 0:\n",
    "        print(f'Iter {iter}/{max_iter_search}, Value of c: {c.item():.6f}')\n",
    "\n",
    "if (c > max_c) or (iter > max_iter_search):\n",
    "    print(\"Failed to find c satisfying f(x + r) = l within the maximum limit of c and max number of iter.\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Optimization succeeded with c = {c.item():.6f} in {iter} iterations\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r optimized alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI=testI.to(device)\n",
    "r = torch.zeros_like(testI, requires_grad=True, device=device)  # Initialize r as zero\n",
    "label= testY-4 # manually chosen target class label different from true one\n",
    "l = torch.tensor([label]).to(device)  \n",
    "l=l.to(device)\n",
    "l = l.view(1) # to have a batch size equal to 1 and work with CrossEntropy loss\n",
    "print(f\"The true class is {testY}, the new class will be {l[0]}\")\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "def objective(c, r, x, l):\n",
    "    term1 = c * torch.norm(r)\n",
    "    term2 = loss_model(model(x+r), l)\n",
    "    return term1 + term2\n",
    "\n",
    "\n",
    "# Line search to find the minimum c > 0\n",
    "c = 0.005\n",
    "iter=0\n",
    "\n",
    "# Define the optimizer (Adam Optimizer)\n",
    "optimizerAdam = optim.Adam([r])\n",
    "\n",
    "while (c <= max_c) and (iter <= max_iter_search):    \n",
    "\n",
    "    # Perform optimization\n",
    "    loss = objective(c, r, testI, l) #The loss is our objective function\n",
    "    loss.backward()\n",
    "    optimizerAdam.step(closure)\n",
    "\n",
    "\n",
    "    # Evaluate the condition f(x + r) = l\n",
    "    with torch.no_grad():\n",
    "        x_r = torch.clamp(testI + r, 0, 1)  # Ensure x + r ∈ [0, 1]^m\n",
    "        pred = model(x_r)\n",
    "        predicted_label = torch.argmax(pred, dim=1)\n",
    "\n",
    "    # Check if the condition f(x + r) = l is satisfied\n",
    "    if predicted_label == l:\n",
    "        print(f\"Found c = {c:.6f} satisfying f(x + r) = l\")\n",
    "        iter=iter+1\n",
    "        break\n",
    "    else:\n",
    "        iter=iter+1\n",
    "\n",
    "    if (iter) % 20 == 0:\n",
    "        print(f'Iter {iter}/{max_iter_search}, Value of c: {c:.6f}')\n",
    "\n",
    "if (c > max_c) or (iter > max_iter_search):\n",
    "    print(\"Failed to find c satisfying f(x + r) = l within the maximum limit of c and max number of iter.\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Optimization succeeded with c = {c:.6f} in {iter} iterations\")\n",
    "    #print(f\"Perturbation r: {r}\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "\n",
    "    plot_results(testI, r, x_r, testY, l, fail=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Gradient Sign Attack (FGSM)\n",
    "\n",
    "Another famous method to create adversarial examples is Fast Gradient Sign Attack (FGSM). Let $\\theta$ be the parameters of a model, x the input image to the model, y its class and J(θ, x, y) the cost used to train the neural network. Usually, when training a model, we compute the gradient of the cost function with respect to the parameters of the model and update them based on the oppositve (i.e., negative) direction of the gradient to decrease the loss. Here, we can replicate the same reasoning but using the pixel values of the input image instead than the model's parameters and using the gradient direction (i.e., positve) to actually maximize the loss. The idea is thus to modify the pixel values so that the loss is maximized and not minimized. In this way, the perturbation should change the image so that it will be misclassified by the model. In order to keep the changes small, possibly imperceptible to naked eye, we only use the sign of the gradient and multiply it by a small $\\epsilon$ value. Mathematically, the adversarial example is estimated using:\n",
    " $$x_r =x + \\epsilon \\text{sign}(\\Delta_x J(\\theta, x, y))$$\n",
    "\n",
    " The gradient can easily be computed using backpropagation (Adam).\n",
    "\n",
    "\n",
    "[*]` Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy Explaining and harnessing adversarial examples. ICLR. 2015`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "index=10\n",
    "testI, testY = mnist_test.__getitem__(index)\n",
    "X = testI.unsqueeze(0).to(device)\n",
    "print(X.shape)\n",
    "X.requires_grad = True # Important for attack\n",
    "Y=torch.tensor([testY]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(testI.squeeze(), interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title(f\"Correct class is {testY}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code by fixing a `eps`value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = XXXXXXX # perturbation size\n",
    "\n",
    "# Forward pass of X through the model\n",
    "pred_original = model(X)  \n",
    "original_class=XXXXXXXX\n",
    "\n",
    "# Compute loss\n",
    "cost = XXXXXXXX\n",
    "\n",
    "# Zero existing (previous) gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# Compute gradients\n",
    "cost.backward()\n",
    "\n",
    "# FGSM attack code\n",
    "Xr = XXXXXXX\n",
    "Xr = XXXXXXX\n",
    "\n",
    "# Re-classify the perturbed image\n",
    "pred_perturbed = model(Xr)\n",
    "perturbed_class=XXXXXXXXXX    \n",
    "\n",
    "# Print results\n",
    "print(f\"Original Class: {original_class.item()}, Perturbed Class: {perturbed_class.item()}\")\n",
    "\n",
    "r=eps*X.grad.data.sign()\n",
    "\n",
    "if original_class.item()==perturbed_class.item():\n",
    "    print(f\"Optimization failed\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "    plot_results(X, r, Xr, testY, perturbed_class, fail=True)   \n",
    "else:\n",
    "    print(f\"Optimization succesfull\")\n",
    "    print(f\"Norm Perturbation |r|: {torch.norm(r, p=1)}\")\n",
    "    plot_results(X, r, Xr, testY, perturbed_class, fail=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to find the best `eps`value, you will code a function and evalute the successful rate for each `eps`value (number of images where an adversarial examples has been successfully created). \n",
    "\n",
    "**Question**: What's the best `eps`value ? Are the changes imperceptible to a naked human eye ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(X, Y, model, loss_model, eps):\n",
    "\n",
    "    XXXXXXXXXX \n",
    "\n",
    "    return Xr, original_class, perturbed_class, r\n",
    "\n",
    "# Accuracy counter\n",
    "adv_examples = []\n",
    "succes=0\n",
    "eps = XXXXXXX # perturbation size\n",
    "\n",
    "# Loop over all examples in test set\n",
    "for X_batch, Y_batch in test_loader:  # Iterate through batches\n",
    "    for X, Y in zip(X_batch, Y_batch):\n",
    "        \n",
    "        XXXXXXXXXX\n",
    "\n",
    "# Calculate final accuracy for this epsilon\n",
    "Adv_acc = XXXXXXX\n",
    "print(f\"Using epsilon: {eps} we succesfully create {Adv_acc} % adversariale examples\")   \n",
    "\n",
    "# Plot one example\n",
    "index=0\n",
    "plot_results(XXXXXXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "interpreter": {
   "hash": "5e59cd04a9cdc53c5128ea57bd8f9b712fba8f1ae7bfd07c006521541be527e5"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
